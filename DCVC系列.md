
## 2021NIPS, Deep Contextual Video Compression

视频编码技术，如hevc 等，都是使用预测编码技术。首先预测出当前帧率 $\hat{x}_{t}$，再编码一个差值 $x_{t}-\hat{x}_{t}$.编码长度是 $H(x_{t}-\hat{x}_{t})$。显然地，$H(x_{t}-\hat{x}_{t})\geq H(x_{t}|\hat{x}_{t}))$。理论与工程是存在鸿沟的，如果没有深度学习技术的话，直接从预测帧中提取信息来编码当前帧是十分困难的，不如退而求其次，只考虑这一误差项的编码。在预测技术固定的情况下，误差项在统计上会符合某种概率分布，对其编码易于操作。

深度学习技术给了我们探究 $H(x_{t}|\hat{x}_{t})$ 极限的可能。这样的压缩范式称为：条件编码方案。这种编码方案需要解决三个问题：
1. 什么是条件
2. 怎么使用条件
3. 如何学习条件
DCVC 整个系列都在研究这三个问题。

### 架构
![[Pasted image 20250101144912.png]]
#### 条件是什么？
特征信息来自当前帧和上一个解码帧，经加强模块后得到。
#### 怎么使用条件？
编码端，解码端，熵模型同时使用了条件。
#### 如何学习条件？
视频的相邻帧具有很强的相关性，上一解码帧提供了这样的参考。同时，当前帧和上一帧又存在着不同，为此使用 mv 来显式地扭曲该信息。降低了学习的难度。

### 熵模型
![[Pasted image 20250101150703.png]]

采用 AR 的形式，综合融合了三种信息。spatial correlation 引入了非常局部的参考信息，边信息引入了当前帧的全局参考信息，context 则引入了时间轴上的参考信息。

## Temporal Context Mining for Learned  Video Compressionz
在 DCVC 中，在时间轴上，实际上只考虑了上一个时刻的参考，这在视频编码中是次优的，在时间轴上寻找更多的参考有益于视频编码, 这同时给条件的学习带来了困难。
本文的改进点在于从时间轴上获取更多信息，并把条件设计成多尺度的形式以减小学习的难度。

### 架构
![[Pasted image 20250101154446.png]]

#### 条件是什么
多通道的特征 $F$ 被传播与更新，TCM 模块产生的多尺度上下文被编解码端和熵模型使用。mv 信息同样被用来扭曲 $F$
#### 怎么使用条件
编解码器：
![[Pasted image 20250101155023.png]]
编解码器是对称结构，多尺度的条件分别在不同的阶段被融入


熵模型：
![[Pasted image 20250101155056.png]]
多尺度的条件经过融合后被输入到熵模型中。本文的熵模型放弃了 AR。

#### 如何学习条件
![[Pasted image 20250101155418.png]]
$F,v$ 经过下采样后进行扭曲，大尺度的条件融合了小尺度的条件。

## Hybrid Spatial-Temporal Entropy Modelling for Neural Video Compression
视频压缩使用的熵模型大多使用现有的图像压缩中的模型，它们的一个缺点是没有考虑到时间轴上的参考。本文为视频压缩方案设计了一种新的熵模型，来缓和熵模型对时间参考有限的问题。