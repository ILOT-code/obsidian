
## 2021NIPS, Deep Contextual Video Compression

视频编码技术，如hevc 等，都是使用预测编码技术。首先预测出当前帧率 $\hat{x}_{t}$，再编码一个差值 $x_{t}-\hat{x}_{t}$.编码长度是 $H(x_{t}-\hat{x}_{t})$。显然地，$H(x_{t}-\hat{x}_{t})\geq H(x_{t}|\hat{x}_{t}))$。理论与工程是存在鸿沟的，如果没有深度学习技术的话，直接从预测帧中提取信息来编码当前帧是十分困难的，不如退而求其次，只考虑这一误差项的编码。在预测技术固定的情况下，误差项在统计上会符合某种概率分布，对其编码易于操作。

深度学习技术给了我们探究 $H(x_{t}|\hat{x}_{t})$ 极限的可能。这样的压缩范式称为：条件编码方案。这种编码方案需要解决三个问题：
1. 什么是条件
2. 怎么使用条件
3. 如何学习条件
DCVC 整个系列都在研究这三个问题。

### 架构
![[Pasted image 20250101144912.png]]
#### 条件是什么？
特征信息来自当前帧和上一个解码帧，经加强模块后得到。
#### 怎么使用条件？
编码端，解码端，熵模型同时使用了条件。
#### 如何学习条件？
视频的相邻帧具有很强的相关性，上一解码帧提供了这样的参考。同时，当前帧和上一帧又存在着不同，为此使用 mv 来显式地扭曲该信息。这样的对齐降低了学习的难度。

### 熵模型
![[Pasted image 20250101150703.png]]

采用 AR 的形式，综合融合了三种信息。spatial correlation 引入了非常局部的参考信息，边信息引入了当前帧的全局参考信息，context 则引入了时间轴上的参考信息。

## Temporal Context Mining for Learned  Video Compressionz
在 DCVC 中，在时间轴上，实际上只考虑了上一个时刻的参考，这在视频编码中是次优的，在时间轴上寻找更多的参考有益于视频编码, 这同时给条件的学习带来了困难。
本文的改进点在于从时间轴上获取更多信息，并把条件设计成多尺度的形式以减小学习的难度。

### 架构
![[Pasted image 20250101154446.png]]

#### 条件是什么
多通道的特征 $F$ 被传播与更新，TCM 模块产生的多尺度上下文被编解码端和熵模型使用。mv 信息同样被用来扭曲 $F$
#### 怎么使用条件
编解码器：
![[Pasted image 20250101155023.png]]
编解码器是对称结构，多尺度的条件分别在不同的阶段被融入


熵模型：
![[Pasted image 20250101155056.png]]
多尺度的条件经过融合后被输入到熵模型中。本文的熵模型放弃了 AR。

#### 如何学习条件
![[Pasted image 20250101155418.png]]
$F,v$ 经过下采样后进行扭曲，大尺度的条件融合了小尺度的条件。

## Hybrid Spatial-Temporal Entropy Modelling for Neural Video Compression
视频压缩使用的熵模型大多使用现有的图像压缩中的模型，它们的一个缺点是没有考虑到时间轴上的参考。本文为视频压缩方案设计了一种新的熵模型，来缓和熵模型对时间参考有限的问题。

该熵模型完全建立在 TCM 的基础上。

### 时空信息融合的熵模型：
![[Pasted image 20250101162653.png]]

空间信息上的参考实际上采用了 checkboard 的形式，而空间信息上的参考实际上就是融合了 $\hat{y}_{t-1}$ 和 $C_{t}$。$\hat{y}_{y-1}$ 和 $C_{t}$ 是互补的关系，前者在 latent 域上提供了更多参考，后者提供了更多帧间运动的信息。熵模型还会为每个点生成一个量化信息，根据视频内容自适应调整量化值。

### 单模型实现码率调整
码率调整通常通过调整损失函数的 $\lambda$ 来进行，这很不方便。对 latent, 设计了新的量化方式：
![[Pasted image 20250101163936.png]]
global 由用户指定，提供了粗略的量化范围，在模型训练时，global 采样生成。
ch 是一组可学习的参数，分通道进行量化。
sc 是熵模型生成的 spatial-channel-wise 的量化参数。


## Neural Video Compression with Diverse Contexts
上下文的质量极大影响了编码效率。之前的文献设计上下文的想法都很好，但实际的效果很可能不如原先的想法。比如提取光流的模块就很可能根本无法生成正确的光流，因为解码的帧 $\hat{x}_{t-1}$ 具有一定的失真，这种失真甚至会逐渐增加。对特征进行对齐时，直接使用该光流进行对齐，也可能不太恰当。

人为引入的先验知识，能够帮助模型更好的学习。本文分析了之前模型的问题，并设计了相应的解决方法。

### 架构
![[Pasted image 20250101184806.png]]
基于 HEM 进行改进。

### Hierarchical Quality Structure
传统编码器存在着 I, P, B 帧的概念，这种概念最早是为了控制码率，但也提高了编码效率。周期性的提高解码的质量可以生成更准确的上下文，比如说光流 mv，这有效减轻了误差的传播。

HEM 框架中，含有 QP 这样的参数，可以周期性的降低 QP 的值，来提高帧的质量。但作者认为，深度学习对训练分布之外的其他分布不具有很好的鲁棒性，自定义的 QP 层可能无法适应测试集上的分布。

作者首先进行对视频进行分组，为一组中的帧设置不同的损失项权重：
$$
L_{all}=\frac{1}{T}\sum_{t}^{T}(\boldsymbol{w}_{t}\cdot\lambda\cdot dist(x_{t}-\hat{x}_{t})+r_{t})
$$
这种设置可以促使编码器周期性的生成高质量的帧，这样高质量帧的特征会随着 $F$ 进行传递，带来性能增益。

### Group-Based Offset Diversity
$F_{t-1}$ 包含了很复杂的特征，包含了之前所有帧中的信息，而直接使用 $x_{t},\hat{x}_{t-1}$ 之间的光流去对齐它则显得不那么有说服力。之前的研究显示，可变形的对齐方案（引入多样的偏置选择）为图像复原带来了更好的结果。作者为视频压缩设计了类似的方案。

首先在通道维度上把 $F$ 分为 G 组，需要为每一组生成 N 个，共 $G\times N$ 个光流。这些生成的光流以原始的那个光流为基础。Offset Prediction 模块同时会为每一个光流生成置信度 mask。
![[Pasted image 20250101191548.png]]

Cross-group 模块先进行 warp 和 mask 操作，然后，像 PixelShuffle 那样，把这些通道进行重排，顺序变为了 ($N\times G$)，随后的 fusion 把每 N 个通道融合为一个。这样的操作加强了通道间的联系，加强了上下文的丰富性。
![[Pasted image 20250101191717.png]]

### Quadtree Partition-Based Entropy Coding
在熵模型方面，作者设计了四分树的模式来引入更多空间上的参考。

首先把 latent 沿着通道维度分为 4 组，每组内部进行顺序不同的计算策略。每一个阶段解码得到的值会作为参考供下一个阶段使用。


![[Pasted image 20250101192420.png]]