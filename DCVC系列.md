
## 2021NIPS, Deep Contextual Video Compression

视频编码技术，如hevc 等，都是使用预测编码技术。首先预测出当前帧率 $\hat{x}_{t}$，再编码一个差值 $x_{t}-\hat{x}_{t}$.编码长度是 $H(x_{t}-\hat{x}_{t})$。显然地，$H(x_{t}-\hat{x}_{t})\geq H(x_{t}|\hat{x}_{t}))$。理论与工程是存在鸿沟的，如果没有深度学习技术的话，直接从预测帧中提取信息来编码当前帧是十分困难的，不如退而求其次，只考虑这一误差项的编码。在预测技术固定的情况下，误差项在统计上会符合某种概率分布，对其编码易于操作。

深度学习技术给了我们探究 $H(x_{t}|\hat{x}_{t})$ 极限的可能。这样的压缩范式称为：条件编码方案。这种编码方案需要解决三个问题：
1. 什么是条件
2. 怎么使用条件
3. 如何学习条件
DCVC 整个系列都在研究这三个问题。

### 架构
![[Pasted image 20250101144912.png]]
#### 条件是什么？
特征信息来自当前帧和上一个解码帧，经加强模块后得到。
#### 怎么使用条件？
编码端，解码端，熵模型同时使用了条件。
#### 如何学习条件？
视频的相邻帧具有很强的相关性，上一解码帧提供了这样的参考。同时，当前帧和上一帧又存在着不同，为此使用 mv 来显式地扭曲该信息。降低了学习的难度。

### 熵模型
![[Pasted image 20250101150703.png]]

采用 AR 的形式，综合融合了三种信息。spatial correlation 引入了非常局部的参考信息，边信息引入了当前帧的全局