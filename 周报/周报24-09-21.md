这周调研了端到端视频编码的最新进展。
总体上看，性能最好的还是 DCVC 系列，一系列超过 VTM 的方法都是基于 DCVC 改的。有一个奇怪的现象是 24 年的 DCVC-FM 在好几个数据集上表现并不如 23 年的 DCVC-DC。
经过调研，比较吸引我的有如下几篇文章：
- Spatial Decomposition and Temporal Fusion Based  Inter Prediction for Learned Video Compression。这篇文章的方法基于 DCVC-DC，它的改进主要有两点。首先是对 MV 模块的改进，主要操作是把参考帧和当前帧分成高频和低频的两张图片，分别对他们提取 MV 并融合。作者认为这能缓解局部区域运动矢量不一致造成的预测不准确问题。另一个点就是长短期时间上下文融合策略。这里可以结合 DCVC-FM 的作法进行比较，DCVC-FM 是对这个一直在传递的特征 $F_{t}$ 进行调制，这其实很像 LSTM 中做的事。本文的策略就是直接使用 ConvLSTM 来对这个 $F_{t}$ 进行处理，一个 ConvLSTM 的隐藏特征 $H_{t}$ 成为了时间上下文，在 $F_{t}$ 的控制下进行更新。但最后作者的实验感觉很奇怪，在 HEVC 的所有数据集上，结果都显示超过 VTM，但性能第二的是 HEM（也超过了 VTM），可是在 DCVC-DC 的文章中给出的实验表明，该数据集上HEM 又超不过 VTM。
- Implicit Motion Function。这篇文章严格来讲并不能算视频压缩的文章，但它给出了一种提取出相邻两张图片的相似性的方法，