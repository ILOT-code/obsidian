大语言模型在处理各种语言任务时展现了惊人的性能，其中key, value 向量对过去信息的总结提炼能力发挥了重要作用。然而，Key-Value (KV) cache 的存储空间随着输入序列的长度线性增长，这限制了大模型处理长下文任务的能力。为了解决这个问题，我们提出了 GCJCP，它是一种为长下文场景设计的、无需额外训练的 KV cache 通道剪枝方法。与之前的方法孤立看待各个通道不同，我们综合考虑了各通道之间的相互影响，设计了一种更好的通道选择方法。