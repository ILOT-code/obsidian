大语言模型在处理各种语言任务时展现了惊人的性能，其中key, value 向量对过去信息的总结提炼能力发挥了重要作用。然而，Key-Value (KV) cache 的存储空间随着输入序列的长度线性增长，这限制了大模型处理长下文任务的能力。为了解决这个问题，我们提出了 GCJDP，它是一种为长下文场景设计的、无需额外训练的 KV cache 通道剪枝方法。