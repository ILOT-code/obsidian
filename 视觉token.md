
系统提示词、图像、用户问题、已生成的回答这些 token 被一股脑丢给 LLM 来处理。在 LLaVA 模型中，图像 token 的占比非常高。直观的感受是，图像 token 的数量肯定是冗余的，人类在看一张图片时，只会根据问题来专注某一小部分区域，或是专注于图像的某个特点。