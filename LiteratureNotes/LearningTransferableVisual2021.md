---
zotero-key: J6TADE3V
zt-attachments:
  - "640"
title: Learning Transferable Visual Models From Natural Language Supervision
authors:
  - Alec Radford
  - Jong Wook Kim
  - Chris Hallacy
  - Aditya Ramesh
  - Gabriel Goh
  - Sandhini Agarwal
  - Girish Sastry
  - Amanda Askell
  - Pamela Mishkin
  - Jack Clark
  - Gretchen Krueger
  - Ilya Sutskever
doi: 10.48550/arXiv.2103.00020
conference: xxx
citekey: LearningTransferableVisual2021
tags: []
---
# Learning Transferable Visual Models From Natural Language Supervision

**文章链接**: [Zotero](zotero://select/library/items/J6TADE3V) [attachment](<file:///home/ilot/Documents/Zotero/storage/YCV3WJGW/Radford%20%E7%AD%89%20-%202021%20-%20Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision.pdf>)
**网页链接**: [URL](http://arxiv.org/abs/2103.00020)
## Abstract

>[!abstract]
> CLIP 提供了图像与文本对齐的能力，能够把这两种差异极大的信息格式转化到一个相同的特征空间上，进而能够计算出单条文本与单个图像间的匹配程度。
> CLIP 这样的能力赋予了它 zero-shot 的特性：对于特定的下游任务（如图像分类），可以构造出一些提示词，让 CLIP 直接来预测该提示词和图像之间的匹配程度。
> 该模型在大多数任务上表现出非平凡的迁移能力，并且能够与完全监督的基线模型竞争，而无需任何特定数据集的训练。例如，在 ImageNet 上达到了原始 ResNet-50 的准确率，



## Comments

