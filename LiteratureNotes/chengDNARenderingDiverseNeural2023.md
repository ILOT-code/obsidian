---
zotero-key: 8FWKQ337
zt-attachments:
  - "228"
title: "DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-centric Rendering"
authors:
  - Wei Cheng
  - Ruixiang Chen
  - Wanqi Yin
  - Siming Fan
  - Keyu Chen
  - Honglin He
  - Huiwen Luo
  - Zhongang Cai
  - Jingbo Wang
  - Yang Gao
  - Zhengming Yu
  - Zhengyu Lin
  - Daxuan Ren
  - Lei Yang
  - Ziwei Liu
  - Chen Change Loy
  - Chen Qian
  - Wayne Wu
  - Dahua Lin
  - Bo Dai
  - Kwan-Yee Lin
doi: 10.48550/arXiv.2307.10173
conference: xxx
citekey: chengDNARenderingDiverseNeural2023
tags: []
---
# DNA-Rendering: A Diverse Neural Actor Repository for High-Fidelity Human-centric Rendering

**文章链接**: [Zotero](zotero://select/library/items/8FWKQ337) [attachment](<file:///home/ilot/Documents/Zotero/storage/3GIHJBNS/Cheng%20%E7%AD%89%20-%202023%20-%20DNA-Rendering%20A%20Diverse%20Neural%20Actor%20Repository%20for%20High-Fidelity%20Human-centric%20Rendering.pdf>)
**网页链接**: [URL](http://arxiv.org/abs/2307.10173)
## Abstract

>[!abstract]
>Realistic human-centric rendering plays a key role in both computer vision and computer graphics. Rapid progress has been made in the algorithm aspect over the years, yet existing human-centric rendering datasets and benchmarks are rather impoverished in terms of diversity, which are crucial for rendering effect. Researchers are usually constrained to explore and evaluate a small set of rendering problems on current datasets, while real-world applications require methods to be robust across different scenarios. In this work, we present DNA-Rendering, a large-scale, high-fidelity repository of human performance data for neural actor rendering. DNA-Rendering presents several alluring attributes. First, our dataset contains over 1500 human subjects, 5000 motion sequences, and 67.5M frames' data volume. Second, we provide rich assets for each subject -- 2D/3D human body keypoints, foreground masks, SMPLX models, cloth/accessory materials, multi-view images, and videos. These assets boost the current method's accuracy on downstream rendering tasks. Third, we construct a professional multi-view system to capture data, which contains 60 synchronous cameras with max 4096 x 3000 resolution, 15 fps speed, and stern camera calibration steps, ensuring high-quality resources for task training and evaluation. Along with the dataset, we provide a large-scale and quantitative benchmark in full-scale, with multiple tasks to evaluate the existing progress of novel view synthesis, novel pose animation synthesis, and novel identity rendering methods. In this manuscript, we describe our DNA-Rendering effort as a revealing of new observations, challenges, and future directions to human-centric rendering. The dataset, code, and benchmarks will be publicly available at https://dna-rendering.github.io/

## Comments

### 创新点

> [!note] Page 1
> 
> In this work, we present DNA-Rendering, a large-scale, high-fidelity repository of human performance data for neural actor rendering.
> ^RME86NLRa3GIHJBNSp1

> [!note] Page 1
> 
> contains over 1500 human subjects, 5000 motion sequences, and 67.5M frames’ data volume.
> ^QF9K3NPBa3GIHJBNSp1

> [!note] Page 4
> 
> Concretely, the array consists of 48 high-end 2448×2048 industrial cameras, and 12 ultra-high resolution cameras with up to 4096 × 3000 resolution.
> ^TGM5BBKAa3GIHJBNSp4

> [!note] Page 4
> 
> We additionally place eight Kinect cameras to capture additional depth streams as auxiliary geometric data.
> ^4EUHIWU4a3GIHJBNSp4

> [!note] Page 5
> 
> Specifically, we ask each actor to wear three sets of outfits and perform at least three actions in different hallucinated scenarios for each outfit, which maximize the identity scale and diversity.
> ^3XQ4CZIRa3GIHJBNSp5

> [!note] Page 5
> 
> As an auxiliary feature, we also capture a static frame of Apose for actors in each outfit for canonical pose recording, and a frame with only empty background for image matting.
> ^847LZN2Ha3GIHJBNSp5

> [!note] Page 5
> 
> Compared with previous work, to our best knowledge, our dataset contains the largest number of human subjects, covering the most diverse action categories, clothing types, and human-object interaction scenarios.
> ^GRY48B59a3GIHJBNSp5

