---
zotero-key: L2I99PB7
zt-attachments:
  - "185"
title: Learned Image Compression with Mixed Transformer-CNN Architectures
authors:
  - Jinming Liu
  - Heming Sun
  - Jiro Katto
doi: 10.48550/arXiv.2303.14978
conference: xxx
citekey: liu2023-learned
tags:
  - ObsCite
---
# Learned Image Compression with Mixed Transformer-CNN Architectures

**æ–‡ç« é“¾æŽ¥**: [Zotero](zotero://select/library/items/L2I99PB7) 
**ç½‘é¡µé“¾æŽ¥**: [URL](http://arxiv.org/abs/2303.14978)
## Abstract

>[!abstract]
>Learned image compression (LIC) methods have exhibited promising progress and superior rate-distortion performance compared with classical image compression standards. Most existing LIC methods are Convolutional Neural Networks-based (CNN-based) or Transformer-based, which have different advantages. Exploiting both advantages is a point worth exploring, which has two challenges: 1) how to effectively fuse the two methods? 2) how to achieve higher performance with a suitable complexity? In this paper, we propose an efficient parallel Transformer-CNN Mixture (TCM) block with a controllable complexity to incorporate the local modeling ability of CNN and the non-local modeling ability of transformers to improve the overall architecture of image compression models. Besides, inspired by the recent progress of entropy estimation models and attention modules, we propose a channel-wise entropy model with parameter-efficient swin-transformer-based attention (SWAtten) modules by using channel squeezing. Experimental results demonstrate our proposed method achieves state-of-the-art rate-distortion performances on three different resolution datasets (i.e., Kodak, Tecnick, CLIC Professional Validation) compared to existing LIC methods. The code is at https://github.com/jmliu206/LIC_TCM.

## Comments

### å‰ç½®å·¥ä½œ

> [!note] Page 1
> 
> For CNNbased example, Cheng et al. [6] proposed a residual blockbased image compression model. For transformer-based example, Zou et al. [37] tried a swin-transformer-based image compression model. These two kinds of methods have different advantages.
> 
> ---
> ðŸ”¤å¯¹äºŽåŸºäºŽCNNçš„ä¾‹å­ï¼ŒChengç­‰äºº[6]æå‡ºäº†ä¸€ç§åŸºäºŽæ®‹å·®å—çš„å›¾åƒåŽ‹ç¼©æ¨¡åž‹ã€‚å¯¹äºŽåŸºäºŽå˜æ¢å™¨çš„ä¾‹å­ï¼ŒZouç­‰äºº[37]å°è¯•äº†ä¸€ç§åŸºäºŽswin-transformerçš„å›¾åƒåŽ‹ç¼©æ¨¡åž‹ã€‚è¿™ä¸¤ç§æ–¹æ³•æœ‰ä¸åŒçš„ä¼˜ç‚¹ã€‚ðŸ”¤
> ^89J8R5NZaFDXJXK2Wp1

> [!note] Page 4
> 
> The Residual Block with stride (RBS), Residual Block Upsampling (RBU) and subpixel conv3x3 are proposed by [6].
> 
> ---
> ðŸ”¤[6]æå‡ºäº†å…·æœ‰æ­¥é•¿çš„æ®‹å·®å—ï¼ˆRBSï¼‰ã€æ®‹å·®å—ä¸Šé‡‡æ ·ï¼ˆRBUï¼‰å’Œå­åƒç´ conv3x3ã€‚ðŸ”¤
> ^DF3G3WY3aFDXJXK2Wp4

### é»„è‰²

> [!note] Page 1
> 
> 1) how to effectively fuse the two methods? 2) how to achieve higher performance with a suitable complexity?
> 
> ---
> ðŸ”¤1ï¼‰ å¦‚ä½•æœ‰æ•ˆåœ°èžåˆè¿™ä¸¤ç§æ–¹æ³•ï¼Ÿ2ï¼‰ å¦‚ä½•åœ¨é€‚å½“çš„å¤æ‚åº¦ä¸‹å®žçŽ°æ›´é«˜çš„æ€§èƒ½ï¼ŸðŸ”¤
> ^GR9KAJ7TaFDXJXK2Wp1

### ç»¿è‰²

> [!note] Page 1
> 
> we propose an efficient parallel Transformer-CNN Mixture (TCM) block with a controllable complexity to incorporate the local modeling ability of CNN and the non-local modeling ability of transformers to improve the overall architecture of image compression models.
> 
> ---
> ðŸ”¤æˆ‘ä»¬æå‡ºäº†ä¸€ç§å…·æœ‰å¯æŽ§å¤æ‚æ€§çš„é«˜æ•ˆå¹¶è¡Œå˜æ¢å™¨CNNæ··åˆï¼ˆTCMï¼‰å—ï¼Œä»¥ç»“åˆCNNçš„å±€éƒ¨å»ºæ¨¡èƒ½åŠ›å’Œå˜æ¢å™¨çš„éžå±€éƒ¨å»ºæ¨¡èƒ½åŠ›æ¥æ”¹è¿›å›¾åƒåŽ‹ç¼©æ¨¡åž‹çš„æ•´ä½“æž¶æž„ã€‚ðŸ”¤
> ^E8LCCYVRaFDXJXK2Wp1

> [!note] Page 2
> 
> To overcome that problem, we try to move attention modules to the channel-wise entropy model which has 1/16 input size compared with that of main path to reduce complexity.
> 
> ---
> ðŸ”¤ä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬è¯•å›¾å°†æ³¨æ„åŠ›æ¨¡å—è½¬ç§»åˆ°ä¿¡é“ç†µæ¨¡åž‹ä¸­ï¼Œä¸Žä¸»è·¯å¾„ç›¸æ¯”ï¼Œè¯¥æ¨¡åž‹çš„è¾“å…¥å¤§å°ä¸º1/16ï¼Œä»¥é™ä½Žå¤æ‚æ€§ã€‚ðŸ”¤
> ^43WNX8WQaFDXJXK2Wp2

> [!note] Page 4
> 
> In order to combine the residual network with the Swin-Transformer more effectively, we divide TCM into two stages with similar processes.
> 
> ---
> ðŸ”¤ä¸ºäº†æ›´æœ‰æ•ˆåœ°å°†æ®‹å·®ç½‘ç»œä¸ŽSwinå˜åŽ‹å™¨ç›¸ç»“åˆï¼Œæˆ‘ä»¬å°†TCMåˆ†ä¸ºä¸¤ä¸ªè¿‡ç¨‹ç›¸ä¼¼çš„é˜¶æ®µã€‚ðŸ”¤
> ^BPW5EY6NaFDXJXK2Wp4

> [!note] Page 4
> 
> The benefit of this is that the residual networks are inserted into the common two consecutive Swin-transformer blocks, which can be more effective for feature fusion.
> 
> ---
> ðŸ”¤è¿™æ ·åšçš„å¥½å¤„æ˜¯å°†æ®‹å·®ç½‘ç»œæ’å…¥åˆ°å…¬å…±çš„ä¸¤ä¸ªè¿žç»­çš„Swinå˜æ¢å™¨å—ä¸­ï¼Œè¿™å¯ä»¥æ›´æœ‰æ•ˆåœ°è¿›è¡Œç‰¹å¾èžåˆã€‚ðŸ”¤
> ^UNJS86FRaFDXJXK2Wp4

### è“è‰²

> [!note] Page 4
> 
> This suggests that our model pays more attention to neighbor regions, and has a similar local modeling ability of CNN.
> 
> ---
> ðŸ”¤è¿™è¡¨æ˜Žæˆ‘ä»¬çš„æ¨¡åž‹æ›´åŠ å…³æ³¨ç›¸é‚»åŒºåŸŸï¼Œå¹¶ä¸”å…·æœ‰ä¸ŽCNNç›¸ä¼¼çš„å±€éƒ¨å»ºæ¨¡èƒ½åŠ›ã€‚ðŸ”¤
> ^S5PXNVA6aFDXJXK2Wp4

> [!note] Page 5
> 
> This means that our model also has the long-distance modeling ability of transformers.
> 
> ---
> ðŸ”¤è¿™æ„å‘³ç€æˆ‘ä»¬çš„æ¨¡åž‹ä¹Ÿå…·æœ‰å˜åŽ‹å™¨çš„è¿œç¨‹å»ºæ¨¡èƒ½åŠ›ã€‚ðŸ”¤
> ^LRAHEFYLaFDXJXK2Wp5

> [!note] Page 5
> 
> This shows that our model has better modeling ability compared to the CNNbased model.
> 
> ---
> ðŸ”¤è¿™è¡¨æ˜Žï¼Œä¸ŽåŸºäºŽç»†èƒžç¥žç»ç½‘ç»œçš„æ¨¡åž‹ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ¨¡åž‹å…·æœ‰æ›´å¥½çš„å»ºæ¨¡èƒ½åŠ›ã€‚ðŸ”¤
> ^F2YUER95aFDXJXK2Wp5

### ç´«è‰²

> [!note] Page 2
> 
> efficiently incorporate the local modeling ability of CNN and the non-local modeling ability of transformers, while maintaining controllable complexity.
> 
> ---
> ðŸ”¤æœ‰æ•ˆåœ°ç»“åˆäº†CNNçš„å±€éƒ¨å»ºæ¨¡èƒ½åŠ›å’Œå˜åŽ‹å™¨çš„éžå±€éƒ¨å»ºæ¨¡èƒ½åŠ›ï¼ŒåŒæ—¶ä¿æŒå¯æŽ§çš„å¤æ‚æ€§ã€‚ðŸ”¤
> ^8J4JQ9NFaFDXJXK2Wp2

> [!note] Page 6
> 
> It suggests that the model with SWAtten can have less information loss and get a higher quality decompressed image.
> 
> ---
> ðŸ”¤ç»“æžœè¡¨æ˜Žï¼ŒSWAttenæ¨¡åž‹å¯ä»¥å‡å°‘ä¿¡æ¯æŸå¤±ï¼Œå¾—åˆ°æ›´é«˜è´¨é‡çš„è§£åŽ‹ç¼©å›¾åƒã€‚ðŸ”¤
> ^84KQ5QWQaFDXJXK2Wp6

