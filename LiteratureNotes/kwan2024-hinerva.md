---
zotero-key: ELZIKZKE
zt-attachments:
  - "290"
title: "HiNeRV: Video Compression with Hierarchical Encoding-based Neural Representation"
authors:
  - Ho Man Kwan
  - Ge Gao
  - Fan Zhang
  - Andrew Gower
  - David Bull
doi: 10.5555/3666122.3669299
conference: xxx
citekey: kwan2024-hinerva
tags: []
---
# HiNeRV: Video Compression with Hierarchical Encoding-based Neural Representation

**æ–‡ç« é“¾æ¥**: [Zotero](zotero://select/library/items/ELZIKZKE) [attachment](<file:///home/ilot/Zotero/storage/NXTAQGZ4/Kwan%20%E7%AD%89%20-%202024%20-%20HiNeRV%20Video%20Compression%20with%20Hierarchical%20Encodi.pdf>)
**ç½‘é¡µé“¾æ¥**: [URL](http://arxiv.org/abs/2306.09818)
## Abstract

>[!abstract]
>åœ¨è§†é¢‘å‹ç¼©é¢†åŸŸï¼Œç°æœ‰çš„ INR-based æ–¹æ³•æ— æ³•è¾¾åˆ°æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œè¿™å¯èƒ½å’Œå®ƒä»¬ç®€å•çš„ç»“æ„æœ‰å…³ï¼Œé™åˆ¶äº†å®ƒä»¬çš„å®¹é‡ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å…·æœ‰å¤šä¸ªç»“æ„ã€å±‚æ¬¡å¤æ‚çš„ç½‘ç»œç»“æ„ï¼Œå¤§å¤§æå‡äº†æ€§èƒ½ã€‚
>åœ¨ UVG å’Œ MCL-JCV æ•°æ®é›†ä¸Šï¼Œæ¯” HNeRV èŠ‚çœ 72%, æ¯” DCVC èŠ‚çœ 43.4%ã€‚

## Method

è§†é¢‘ $V\in \mathbb{R}^{T\times H\times W\times C}$ . è§†é¢‘ä¸­çš„æ¯ä¸€å¸§éƒ½è¢«åˆ†æˆäº† $M\times M$ çš„å—ï¼Œpatch åæ ‡çš„åæ ‡æ˜¯ $(i,j,t),0\leq t<T,0\leq j<\frac{H}{M},0\leq i<\frac{W}{M}$
è¯¥ patchåœ¨ç»è¿‡ä¸€ç³»åˆ—å·ç§¯ä¹‹åï¼Œå¤§å°ä¼šå˜ï¼Œ$M_{1}\times M_{1}$ã€‚ä½†æ˜¯ä¾ç„¶å¯ä»¥æŠŠè¿™ä¸ª patch åæ ‡æ˜ å°„åˆ°å…¨å±€çš„åæ ‡ï¼Œå‡è®¾ä¸€ä¸ª patch-based åæ ‡æ˜¯ $u_{patch},v_{{patch}}$ï¼Œé‚£ä¹ˆå®ƒæ˜ å°„å›çš„å…¨å±€åæ ‡ (frame -based)
å°±æ˜¯ $u_{frame}=j\times M_{1}+u_{patch},v_{frame}=i\times M_{1}+v_{patch}$



Grid é‡‡ç”¨äº† [[lee2023-ffnerv|(Joo Chan Lee, 2023)]] ä¸­çš„å¤šæ—¶é—´åˆ†è¾¨ç‡ gridï¼Œä¸åŒçš„æ˜¯ï¼Œ[[lee2023-ffnerv|(Joo Chan Lee, 2023)]]
æ˜¯ frame-wise çš„ï¼Œä¸€æ¬¡ç”Ÿæˆä¸€æ•´ä¸ªå¸§ï¼Œåªåœ¨æ—¶é—´è½´ä¸Šè¿›è¡Œçº¿æ€§æ’å€¼ï¼Œè€Œæœ¬æ–‡æ˜¯ patch-wise çš„ (å½“ç„¶ä¹Ÿèƒ½æ‰©å±•åˆ° frame-wise)ï¼Œä¼šä½¿ç”¨ frame-based çš„ä¸‰ä¸ªåæ ‡è½´è¿›è¡Œæ’å€¼ã€‚è¿™äº› grid çš„å½¢çŠ¶æ˜¯ $\lfloor\frac{T_{grid}}{2^l}\rfloor\times H_{grid}\times W_{grid}\times(C_{grid}\times2^l),\mathrm{for~}0\leq l<L_{grid}.$

åœ¨æ¯ä¸€ä¸ª HiNeRV å—ä¸­ï¼Œä¼šè·å¾—ä¸¤ä¸ªè¾“å…¥ã€‚
$X_{n}\in \mathbb{R}^{M_{n}\times M_{n}\times C_{n}}$, $C_{n}=\left\lfloor  \frac{C_{0}}{R^{n-1}}  \right\rfloor$ ä½¿ç”¨åŒçº¿æ€§æ’å€¼ä¸Šé‡‡æ ·(ä½œè€…è®¤ä¸ºï¼Œæ— å‚çš„åŒçº¿æ€§æ’å€¼ç›¸æ¯”ä½¿ç”¨å·ç§¯ï¼Œåœ¨å‹ç¼©ä»»åŠ¡ä¸­æ›´å¥½)ï¼Œ$M_{{n+1}}=M_{n}\times S_{n+1}$ã€‚$S$ æ˜¯ä¸Šé‡‡æ ·ç³»æ•°ã€‚åŒçº¿æ€§æ’å€¼ä¼šäº§ç”Ÿå¹³æ»‘çš„å›¾åƒï¼Œä¼šå¯¼è‡´åç»­çš„ç½‘ç»œéš¾ä»¥äº§ç”Ÿé«˜é¢‘çš„è¾“å‡ºï¼Œå›¾åƒçš„é«˜é¢‘ç»†èŠ‚éš¾ä»¥ç»´æŒã€‚grid-based encoding æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜çš„ä¸€ç§æ–¹æ³•ï¼Œä½†å®ƒåŒæ—¶æ„å‘³ç€å·¨å¤§çš„ç©ºé—´æŸè€—ï¼Œå¯¹äº N ä¸ªå—è€Œè¨€éš¾ä»¥æ¥å—ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§åˆ†å±‚ç¼–ç æ–¹æ³•ã€‚

æ¯ä¸€ä¸ª HiNeRV å—ï¼Œä¹Ÿå­˜åœ¨ç€ä¸€ä¸ª temporal local grid. å…·æœ‰ $L_{local}$ ä¸ªå½¢çŠ¶æ˜¯ $\left\lfloor  \frac{T_{local}}{2^l}  \right\rfloor *S_{n}\times S_{n}\times \left( \left\lfloor   \frac{C_{local}}{R^{n-1}}  \right\rfloor \times 2^l \right )$ï¼Œ$S_{n}$ å¾ˆå°ï¼Œè¿™äº›ç½‘æ ¼çš„å‚æ•°é‡å¾ˆå°ã€‚å¯¹äº patch ä¸­çš„åæ ‡ $(u_{p},v_{p})$ï¼Œç”±äºç»™äº† patch-indexï¼Œå¯ä»¥å…ˆæŠŠå®ƒä»¬æ˜ å°„åˆ°å…¨å±€åæ ‡ $(u_{f},v_{f})$, æœ€åå¾—åˆ° local åæ ‡ $(u_{l}=u_{f}~MOD~ S_{n},v_{l}=v_{f}~MOD~S_{n})$ã€‚
ä½¿ç”¨è¯¥åæ ‡ $(t,u_{l},v_{l})$ åœ¨ temporal local grid ä¸Šå–å¾—å¯¹åº”çš„å€¼ï¼ˆä¸‰çº¿æ€§æ’å€¼ï¼‰

![[Pasted image 20240904162739.png]]
## Comments

### å…ˆå‰ç ”ç©¶çš„é—®é¢˜

> [!note] Page 1
> 
> However, existing INR-based methods have failed to deliver rate quality performance comparable with the state of the art in video compression.
> 
> ---
> ğŸ”¤ç„¶è€Œï¼Œç°æœ‰çš„åŸºäº INR çš„æ–¹æ³•æœªèƒ½æä¾›ä¸è§†é¢‘å‹ç¼©é¢†åŸŸçš„æœ€æ–°æŠ€æœ¯ç›¸å½“çš„é€Ÿç‡è´¨é‡æ€§èƒ½ã€‚ğŸ”¤
> ^ZDU6Y7D6aNXTAQGZ4p1

> [!note] Page 1
> 
> However, existing INR-based algorithms remain significantly inferior to state-of-the-art standard-based [58, 52, 9] and learning-based codecs [28, 46, 29, 30, 37]. For example, none of these INR-based codecs can compete with HEVC x265 [3] (veryslow preset).
> 
> ---
> ğŸ”¤ç„¶è€Œï¼Œç°æœ‰çš„åŸºäº INR çš„ç®—æ³•ä»ç„¶æ˜æ˜¾ä¸å¦‚æœ€å…ˆè¿›çš„åŸºäºæ ‡å‡†çš„ [58,52,9] å’ŒåŸºäºå­¦ä¹ çš„ç¼–è§£ç å™¨ [28,46,29,30,37]ã€‚ä¾‹å¦‚ï¼Œè¿™äº›åŸºäº INR çš„ç¼–è§£ç å™¨éƒ½æ— æ³•ä¸ HEVC x265 [3]ï¼ˆéå¸¸æ…¢çš„é¢„è®¾ï¼‰ç«äº‰ã€‚ğŸ”¤
> ^6PZNCQENaNXTAQGZ4p1

> [!note] Page 2
> 
> In addition, most existing work employs Fourier-based positional encoding [40]; this has a long training time and can only achieve sub-optimal reconstruction quality [12, 31, 6]
> 
> ---
> ğŸ”¤æ­¤å¤–ï¼Œå¤§å¤šæ•°ç°æœ‰å·¥ä½œéƒ½é‡‡ç”¨åŸºäºå‚…é‡Œå¶çš„ä½ç½®ç¼–ç [40]ï¼›è¿™æœ‰å¾ˆé•¿çš„è®­ç»ƒæ—¶é—´å¹¶ä¸”åªèƒ½è¾¾åˆ°æ¬¡ä¼˜çš„é‡å»ºè´¨é‡[12,31,6]ğŸ”¤
> ^MEG52AWMaNXTAQGZ4p2

### åˆ›æ–°ç‚¹

> [!note] Page 2
> 
> We replace commonly used sub-pixel conventional layers [47] in existing INRs for upsampling [12, 31, 6, 27, 11] by a new upsampling layer which embodies bilinear interpolation with hierarchical encoding that is sampled from multi-resolution local feature grids.
> 
> ---
> ğŸ”¤æˆ‘ä»¬ç”¨æ–°çš„ä¸Šé‡‡æ ·å±‚æ›¿æ¢äº†ç°æœ‰ INR ä¸­å¸¸ç”¨çš„å­åƒç´ ä¼ ç»Ÿå±‚ [47]ï¼Œç”¨äºä¸Šé‡‡æ · [12,31,6,27,11]ï¼Œè¯¥å±‚ä½“ç°äº†ä»å¤šåˆ†è¾¨ç‡å±€éƒ¨ç‰¹å¾ç½‘æ ¼é‡‡æ ·çš„åˆ†å±‚ç¼–ç çš„åŒçº¿æ€§æ’å€¼ã€‚ğŸ”¤
> ^CWLJZA9NaNXTAQGZ4p2

### ç–‘æƒ‘ç‚¹

> [!note] Page 7
> 
> using quantization-aware training with Quant-Noise [51] to minimize the quantization error.
> 
> ---
> ğŸ”¤ä½¿ç”¨é‡åŒ–æ„ŸçŸ¥è®­ç»ƒå’Œ Quant-Noise [51] æ¥æœ€å°åŒ–é‡åŒ–è¯¯å·®ã€‚ğŸ”¤
> ^VCXYDLZBaNXTAQGZ4p7

### æ€§èƒ½æˆç»©

> [!note] Page 1
> 
> The proposed method has been evaluated on both UVG and MCL-JCV datasets for video compression, demonstrating significant improvement over all existing INRs baselines and competitive performance when compared to learning-based codecs (72.3% overall bit rate saving over HNeRV and 43.4% over DCVC on the UVG dataset, measured in PSNR). 1
> 
> ---
> ğŸ”¤æ‰€æå‡ºçš„æ–¹æ³•å·²åœ¨ç”¨äºè§†é¢‘å‹ç¼©çš„ UVG å’Œ MCL-JCV æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œä¸åŸºäºå­¦ä¹ çš„ç¼–è§£ç å™¨ç›¸æ¯”ï¼Œè¯æ˜äº†æ‰€æœ‰ç°æœ‰ INR åŸºçº¿å’Œç«äº‰æ€§èƒ½çš„æ˜¾ç€æ”¹è¿›ï¼ˆæ¯” HNeRV æ€»ä½“æ¯”ç‰¹ç‡èŠ‚çœ 72.3%ï¼Œæ¯” DCVC èŠ‚çœ 43.4%ï¼‰åœ¨ UVG æ•°æ®é›†ä¸Šï¼Œä»¥ PSNR ä¸ºå•ä½æµ‹é‡ï¼‰ã€‚ 1ğŸ”¤
> ^XJ764926aNXTAQGZ4p1

### æŠ€æœ¯ç»†èŠ‚

> [!note] Page 4
> 
> In FFNeRV, linear interpolation over the temporal dimension is used to obtain a slice that is used as the input feature map. In our case, we utilize both of the frame index and the frame-based coordinates, i.e., (uframe, vframe, t), for interpolating the feature patches.
> 
> ---
> ğŸ”¤åœ¨ FFNeRV ä¸­ï¼Œä½¿ç”¨æ—¶é—´ç»´åº¦ä¸Šçš„çº¿æ€§æ’å€¼æ¥è·å–ç”¨ä½œè¾“å…¥ç‰¹å¾å›¾çš„åˆ‡ç‰‡ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨å¸§ç´¢å¼•å’ŒåŸºäºå¸§çš„åæ ‡ï¼Œå³ï¼ˆuframeï¼Œvframeï¼Œtï¼‰æ¥æ’å€¼ç‰¹å¾å—ã€‚ğŸ”¤
> ^JLM9R3WGaNXTAQGZ4p4

> [!note] Page 4
> 
> To maintain a compact multi-resolution grid, we increase the number of channels when reducing the temporal resolution at each grid level
> 
> ---
> ğŸ”¤ä¸ºäº†ä¿æŒç´§å‡‘çš„å¤šåˆ†è¾¨ç‡ç½‘æ ¼ï¼Œæˆ‘ä»¬åœ¨é™ä½æ¯ä¸ªç½‘æ ¼çº§åˆ«çš„æ—¶é—´åˆ†è¾¨ç‡æ—¶å¢åŠ é€šé“æ•°ğŸ”¤
> ^LH3HIX4AaNXTAQGZ4p4

> [!note] Page 5
> 
> Previous work [12] has shown that bilinear interpolation does not perform as well as convolutional layers. However, we observed that it is actually a better choice when the parameter count is fixed.
> 
> ---
> ğŸ”¤ä¹‹å‰çš„å·¥ä½œ [12] è¡¨æ˜åŒçº¿æ€§æ’å€¼çš„æ€§èƒ½ä¸å¦‚å·ç§¯å±‚ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œå½“å‚æ•°æ•°é‡å›ºå®šæ—¶ï¼Œå®ƒå®é™…ä¸Šæ˜¯ä¸€ä¸ªæ›´å¥½çš„é€‰æ‹©ã€‚ğŸ”¤
> ^4H4PUXC9aNXTAQGZ4p5

> [!note] Page 5
> 
> While we can generate high-resolution maps using parameter-free bilinear interpolation, the resulting maps are smoothed, and subsequent neural network layers may struggle to produce high-frequency output from them. One way to model high-frequency signals is to introduce positional encoding [40] during upsampling.
> 
> ---
> ğŸ”¤è™½ç„¶æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ— å‚æ•°åŒçº¿æ€§æ’å€¼ç”Ÿæˆé«˜åˆ†è¾¨ç‡åœ°å›¾ï¼Œä½†ç”Ÿæˆçš„åœ°å›¾æ˜¯å¹³æ»‘çš„ï¼Œåç»­çš„ç¥ç»ç½‘ç»œå±‚å¯èƒ½éš¾ä»¥ä»ä¸­äº§ç”Ÿé«˜é¢‘è¾“å‡ºã€‚å¯¹é«˜é¢‘ä¿¡å·å»ºæ¨¡çš„ä¸€ç§æ–¹æ³•æ˜¯åœ¨ä¸Šé‡‡æ ·æœŸé—´å¼•å…¥ä½ç½®â€‹â€‹ç¼–ç [40]ã€‚ğŸ”¤
> ^Z7J67SEIaNXTAQGZ4p5

> [!note] Page 5
> 
> To address this limitation, we introduce a novel grid-based encoding approach called hierarchical encoding, which boosts the upsampling capability of bilinear interpolation without significantly increasing the storage cost.
> 
> ---
> ğŸ”¤ä¸ºäº†è§£å†³è¿™ä¸ªé™åˆ¶ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„åŸºäºç½‘æ ¼çš„ç¼–ç æ–¹æ³•ï¼Œç§°ä¸ºåˆ†å±‚ç¼–ç ï¼Œå®ƒå¢å¼ºäº†åŒçº¿æ€§æ’å€¼çš„ä¸Šé‡‡æ ·èƒ½åŠ›ï¼Œè€Œä¸ä¼šæ˜¾ç€å¢åŠ å­˜å‚¨æˆæœ¬ã€‚ğŸ”¤
> ^RJNNZ8FQaNXTAQGZ4p5

> [!note] Page 6
> 
> When configuring HiNeRV as a patch-wise representation, we perform computation in overlapped patches, where we refer to the overlapped part as paddings, and the amount of padding pixels depends on the network configuration (e.g. the kernel sizes and/or the number of bilinear interpolation/convolutional layers).
> 
> ---
> ğŸ”¤å½“å°† HiNeRV é…ç½®ä¸º patch-wise è¡¨ç¤ºæ—¶ï¼Œæˆ‘ä»¬åœ¨é‡å çš„ patch ä¸­æ‰§è¡Œè®¡ç®—ï¼Œå…¶ä¸­æˆ‘ä»¬å°†é‡å éƒ¨åˆ†ç§°ä¸ºå¡«å……ï¼Œå¡«å……åƒç´ çš„æ•°é‡å–å†³äºç½‘ç»œé…ç½®ï¼ˆä¾‹å¦‚å†…æ ¸å¤§å°å’Œ/æˆ–åŒçº¿æ€§çš„æ•°é‡ï¼‰æ’å€¼/å·ç§¯å±‚ï¼‰ã€‚ğŸ”¤
> ^7KXXMTLZaNXTAQGZ4p6

